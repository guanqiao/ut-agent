"""CLI å…¥å£æ¨¡å—."""

import asyncio
from pathlib import Path
from typing import Optional

import typer
from rich.console import Console
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.table import Table
from rich import box

from ut_agent.graph import create_test_generation_graph, AgentState
from ut_agent.models import list_available_providers, get_llm
from ut_agent.config import settings
from ut_agent.tools.test_executor import (
    check_java_environment,
    check_maven_environment,
    check_node_environment,
)

app = typer.Typer(
    name="ut-agent",
    help="AIé©±åŠ¨çš„å•å…ƒæµ‹è¯•ç”ŸæˆAgent",
    no_args_is_help=True,
)
console = Console()


def version_callback(value: bool) -> None:
    """ç‰ˆæœ¬å›è°ƒ."""
    if value:
        console.print("[bold blue]UT-Agent[/bold blue] version 0.1.0")
        raise typer.Exit()


@app.callback()
def main(
    version: bool = typer.Option(
        None, "--version", "-v", callback=version_callback, is_eager=True
    ),
) -> None:
    """UT-Agent: AIé©±åŠ¨çš„å•å…ƒæµ‹è¯•ç”Ÿæˆå™¨."""
    pass


@app.command(name="generate")
def generate_tests(
    project: Path = typer.Argument(
        ..., help="é¡¹ç›®è·¯å¾„", exists=True, file_okay=False, dir_okay=True
    ),
    project_type: str = typer.Option(
        "auto", "--type", "-t", help="é¡¹ç›®ç±»å‹ (auto/java/vue/react/typescript)"
    ),
    coverage_target: float = typer.Option(
        settings.default_coverage_target, "--coverage-target", "-c",
        help="è¦†ç›–ç‡ç›®æ ‡ (0-100)"
    ),
    max_iterations: int = typer.Option(
        settings.max_iterations, "--max-iterations", "-i",
        help="æœ€å¤§è¿­ä»£æ¬¡æ•°"
    ),
    llm_provider: str = typer.Option(
        settings.default_llm_provider, "--llm", "-l",
        help="LLM æä¾›å•†"
    ),
    dry_run: bool = typer.Option(
        False, "--dry-run", help="ä»…ç”Ÿæˆæµ‹è¯•ï¼Œä¸ä¿å­˜"
    ),
    incremental: bool = typer.Option(
        False, "--incremental", "-inc",
        help="å¢é‡æ¨¡å¼ï¼šä»…å¯¹å˜æ›´ä»£ç ç”Ÿæˆæµ‹è¯•"
    ),
    base_ref: Optional[str] = typer.Option(
        None, "--base", "-b",
        help="åŸºå‡†Gitå¼•ç”¨ (é»˜è®¤: HEAD~1)"
    ),
    head_ref: Optional[str] = typer.Option(
        None, "--head",
        help="ç›®æ ‡Gitå¼•ç”¨ (é»˜è®¤: HEAD)"
    ),
    html_report: bool = typer.Option(
        False, "--html-report", "-r",
        help="ç”ŸæˆHTMLè¦†ç›–ç‡æŠ¥å‘Š"
    ),
) -> None:
    """ç”Ÿæˆå•å…ƒæµ‹è¯•."""
    console.print(Panel.fit(
        "[bold blue]ğŸ§ª UT-Agent[/bold blue] - AIé©±åŠ¨çš„å•å…ƒæµ‹è¯•ç”Ÿæˆå™¨",
        border_style="blue"
    ))

    # éªŒè¯å‚æ•°
    if coverage_target < 0 or coverage_target > 100:
        console.print("[red]é”™è¯¯: è¦†ç›–ç‡ç›®æ ‡å¿…é¡»åœ¨ 0-100 ä¹‹é—´[/red]")
        raise typer.Exit(1)

    # æ˜¾ç¤ºé…ç½®
    config_table = Table(box=box.ROUNDED)
    config_table.add_column("é…ç½®é¡¹", style="cyan")
    config_table.add_column("å€¼", style="green")
    config_table.add_row("é¡¹ç›®è·¯å¾„", str(project))
    config_table.add_row("é¡¹ç›®ç±»å‹", project_type)
    config_table.add_row("è¦†ç›–ç‡ç›®æ ‡", f"{coverage_target}%")
    config_table.add_row("æœ€å¤§è¿­ä»£æ¬¡æ•°", str(max_iterations))
    config_table.add_row("LLM æä¾›å•†", llm_provider)
    config_table.add_row("Dry Run", "æ˜¯" if dry_run else "å¦")
    config_table.add_row("å¢é‡æ¨¡å¼", "æ˜¯" if incremental else "å¦")
    if incremental:
        config_table.add_row("åŸºå‡†å¼•ç”¨", base_ref or "HEAD~1")
        config_table.add_row("ç›®æ ‡å¼•ç”¨", head_ref or "HEAD")
    config_table.add_row("HTMLæŠ¥å‘Š", "æ˜¯" if html_report else "å¦")
    console.print(config_table)
    console.print()

    # è¿è¡Œå·¥ä½œæµ
    asyncio.run(run_generation_workflow(
        project_path=str(project),
        project_type=project_type,
        coverage_target=coverage_target,
        max_iterations=max_iterations,
        llm_provider=llm_provider,
        dry_run=dry_run,
        incremental=incremental,
        base_ref=base_ref,
        head_ref=head_ref,
        html_report=html_report,
    ))


@app.command(name="interactive")
def interactive_mode() -> None:
    """äº¤äº’å¼æ¨¡å¼."""
    console.print(Panel.fit(
        "[bold blue]ğŸ§ª UT-Agent[/bold blue] - äº¤äº’å¼æ¨¡å¼",
        border_style="blue"
    ))

    # é¡¹ç›®è·¯å¾„
    project_path = typer.prompt("è¯·è¾“å…¥é¡¹ç›®è·¯å¾„")
    project = Path(project_path)
    if not project.exists():
        console.print(f"[red]é”™è¯¯: è·¯å¾„ä¸å­˜åœ¨ {project_path}[/red]")
        raise typer.Exit(1)

    # é¡¹ç›®ç±»å‹
    project_type = typer.prompt(
        "é¡¹ç›®ç±»å‹ (auto/java/vue/react/typescript)",
        default="auto"
    )

    # è¦†ç›–ç‡ç›®æ ‡
    coverage_target = float(typer.prompt(
        "è¦†ç›–ç‡ç›®æ ‡ (%)",
        default=str(settings.default_coverage_target)
    ))

    # æœ€å¤§è¿­ä»£æ¬¡æ•°
    max_iterations = int(typer.prompt(
        "æœ€å¤§è¿­ä»£æ¬¡æ•°",
        default=str(settings.max_iterations)
    ))

    # LLM æä¾›å•†
    available_providers = list_available_providers()
    llm_provider = typer.prompt(
        f"LLM æä¾›å•† ({'/'.join(available_providers)})",
        default=settings.default_llm_provider
    )

    # è¿è¡Œ
    asyncio.run(run_generation_workflow(
        project_path=str(project),
        project_type=project_type,
        coverage_target=coverage_target,
        max_iterations=max_iterations,
        llm_provider=llm_provider,
        dry_run=False,
    ))


@app.command(name="ui")
def launch_ui(
    port: int = typer.Option(8501, "--port", "-p", help="ç«¯å£å·"),
    host: str = typer.Option("127.0.0.1", "--host", "-h", help="ä¸»æœºåœ°å€"),
) -> None:
    """å¯åŠ¨ Web UI."""
    console.print(Panel.fit(
        "[bold blue]ğŸš€ å¯åŠ¨ UT-Agent Web UI[/bold blue]",
        border_style="green"
    ))

    try:
        import streamlit.web.cli as stcli
        import sys

        ui_file = Path(__file__).parent / "ui" / "app.py"

        sys.argv = [
            "streamlit",
            "run",
            str(ui_file),
            "--server.port", str(port),
            "--server.address", host,
        ]

        console.print(f"[green]UI å¯åŠ¨åœ¨ http://{host}:{port}[/green]")
        stcli.main()

    except ImportError:
        console.print("[red]é”™è¯¯: æœªå®‰è£… streamlitï¼Œè¯·è¿è¡Œ: pip install streamlit[/red]")
        raise typer.Exit(1)


@app.command(name="ci")
def ci_mode(
    project: Path = typer.Argument(
        ..., help="é¡¹ç›®è·¯å¾„", exists=True, file_okay=False, dir_okay=True
    ),
    project_type: str = typer.Option(
        "auto", "--type", "-t", help="é¡¹ç›®ç±»å‹ (auto/java/vue/react/typescript)"
    ),
    coverage_target: float = typer.Option(
        80.0, "--coverage-target", "-c",
        help="è¦†ç›–ç‡ç›®æ ‡ (0-100)"
    ),
    max_iterations: int = typer.Option(
        5, "--max-iterations", "-i",
        help="æœ€å¤§è¿­ä»£æ¬¡æ•°"
    ),
    llm_provider: str = typer.Option(
        "openai", "--llm", "-l",
        help="LLM æä¾›å•†"
    ),
    output_format: str = typer.Option(
        "json", "--output", "-o",
        help="è¾“å‡ºæ ¼å¼ (json/markdown/summary)"
    ),
    output_file: Optional[Path] = typer.Option(
        None, "--output-file",
        help="è¾“å‡ºæ–‡ä»¶è·¯å¾„"
    ),
    fail_on_coverage: bool = typer.Option(
        False, "--fail-on-coverage",
        help="è¦†ç›–ç‡ä½äºç›®æ ‡æ—¶è¿”å›éé›¶é€€å‡ºç "
    ),
    incremental: bool = typer.Option(
        False, "--incremental", "-inc",
        help="å¢é‡æ¨¡å¼ï¼šä»…å¯¹å˜æ›´ä»£ç ç”Ÿæˆæµ‹è¯•"
    ),
    base_ref: Optional[str] = typer.Option(
        None, "--base", "-b",
        help="åŸºå‡†Gitå¼•ç”¨"
    ),
) -> None:
    """CIæ¨¡å¼ï¼šéäº¤äº’å¼è¿è¡Œï¼Œè¾“å‡ºJSONç»“æœ."""
    from ut_agent.ci import CIRunner
    
    runner = CIRunner(
        project_path=str(project),
        project_type=project_type,
        coverage_target=coverage_target,
        max_iterations=max_iterations,
        llm_provider=llm_provider,
        output_format=output_format,
        output_file=str(output_file) if output_file else None,
        fail_on_coverage=fail_on_coverage,
        incremental=incremental,
        base_ref=base_ref,
    )
    
    exit_code = runner.run_sync()
    raise typer.Exit(exit_code)


@app.command(name="check")
def check_environment() -> None:
    """æ£€æŸ¥ç¯å¢ƒé…ç½®."""
    console.print(Panel.fit(
        "[bold blue]ğŸ” ç¯å¢ƒæ£€æŸ¥[/bold blue]",
        border_style="blue"
    ))

    table = Table(box=box.ROUNDED)
    table.add_column("ç»„ä»¶", style="cyan")
    table.add_column("çŠ¶æ€", style="green")
    table.add_column("ä¿¡æ¯", style="yellow")

    java_ok, java_msg = check_java_environment()
    table.add_row(
        "Java",
        "[green]âœ“[/green]" if java_ok else "[red]âœ—[/red]",
        java_msg
    )

    maven_ok, maven_msg = check_maven_environment()
    table.add_row(
        "Maven",
        "[green]âœ“[/green]" if maven_ok else "[red]âœ—[/red]",
        maven_msg
    )

    node_ok, node_msg = check_node_environment()
    table.add_row(
        "Node.js",
        "[green]âœ“[/green]" if node_ok else "[red]âœ—[/red]",
        node_msg
    )

    available_providers = list_available_providers()
    table.add_row(
        "LLM æä¾›å•†",
        "[green]âœ“[/green]" if available_providers else "[red]âœ—[/red]",
        f"å¯ç”¨: {', '.join(available_providers)}"
    )

    console.print(table)


@app.command(name="mutation")
def run_mutation_tests(
    project: Path = typer.Argument(
        ..., help="é¡¹ç›®è·¯å¾„", exists=True, file_okay=False, dir_okay=True
    ),
    target_classes: Optional[str] = typer.Option(
        None, "--target-classes", "-tc",
        help="ç›®æ ‡ç±» (é€—å·åˆ†éš”, é»˜è®¤: *)"
    ),
    target_tests: Optional[str] = typer.Option(
        None, "--target-tests", "-tt",
        help="ç›®æ ‡æµ‹è¯•ç±» (é€—å·åˆ†éš”, é»˜è®¤: *Test)"
    ),
    mutators: Optional[str] = typer.Option(
        None, "--mutators", "-m",
        help="å˜å¼‚ç®—å­ (é€—å·åˆ†éš”, é»˜è®¤: DEFAULTS)"
    ),
    output_format: str = typer.Option(
        "summary", "--output", "-o",
        help="è¾“å‡ºæ ¼å¼ (json/summary)"
    ),
    suggest_tests: bool = typer.Option(
        True, "--suggest",
        help="ç”Ÿæˆæµ‹è¯•å»ºè®®"
    ),
) -> None:
    """è¿è¡Œå˜å¼‚æµ‹è¯•å¹¶åˆ†æç»“æœ."""
    from ut_agent.tools.mutation_analyzer import MutationAnalyzer
    
    console.print(Panel.fit(
        "[bold purple]ğŸ§¬ å˜å¼‚æµ‹è¯•åˆ†æ[/bold purple]",
        border_style="purple"
    ))
    
    analyzer = MutationAnalyzer(
        project_path=str(project),
        target_classes=target_classes.split(",") if target_classes else None,
        target_tests=target_tests.split(",") if target_tests else None,
        mutators=mutators.split(",") if mutators else None,
    )
    
    console.print("[cyan]æ­£åœ¨è¿è¡Œå˜å¼‚æµ‹è¯•...[/cyan]")
    
    try:
        report = analyzer.run_mutation_tests()
        
        if output_format == "json":
            console.print_json(data=report.to_dict())
        else:
            console.print(analyzer.get_report_summary())
        
        if suggest_tests and report.survived_mutations:
            console.print()
            console.print("[bold yellow]ğŸ“ æµ‹è¯•å»ºè®®[/bold yellow]")
            
            suggestions = analyzer.generate_test_suggestions()
            for i, suggestion in enumerate(suggestions[:10], 1):
                console.print(f"\n{i}. [cyan]{suggestion['source_file']}:{suggestion['line_number']}[/cyan]")
                console.print(f"   æ–¹æ³•: {suggestion['method_name']}")
                console.print(f"   å˜å¼‚ç±»å‹: {suggestion['mutation_type']}")
                console.print(f"   å»ºè®®: {suggestion['suggested_test']}")
            
            if len(suggestions) > 10:
                console.print(f"\n   ... è¿˜æœ‰ {len(suggestions) - 10} ä¸ªå»ºè®®")
        
        if report.survived > 0:
            raise typer.Exit(1)
        
    except Exception as e:
        console.print(f"[red]å˜å¼‚æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}[/red]")
        raise typer.Exit(2)


@app.command(name="config")
def show_config() -> None:
    """æ˜¾ç¤ºå½“å‰é…ç½®."""
    console.print(Panel.fit(
        "[bold blue]âš™ï¸ å½“å‰é…ç½®[/bold blue]",
        border_style="blue"
    ))

    table = Table(box=box.ROUNDED)
    table.add_column("é…ç½®é¡¹", style="cyan")
    table.add_column("å€¼", style="green")

    table.add_row("é»˜è®¤ LLM æä¾›å•†", settings.default_llm_provider)
    table.add_row("OpenAI æ¨¡å‹", settings.openai_model)
    table.add_row("DeepSeek æ¨¡å‹", settings.deepseek_model)
    table.add_row("Ollama æ¨¡å‹", settings.ollama_model)
    table.add_row("Ollama åœ°å€", settings.ollama_base_url)
    table.add_row("é»˜è®¤è¦†ç›–ç‡ç›®æ ‡", f"{settings.default_coverage_target}%")
    table.add_row("æœ€å¤§è¿­ä»£æ¬¡æ•°", str(settings.max_iterations))
    table.add_row("Temperature", str(settings.temperature))

    console.print(table)


@app.command(name="metrics")
def show_metrics() -> None:
    """æ˜¾ç¤ºå½“å‰ç›‘æ§æŒ‡æ ‡."""
    from ut_agent.utils.metrics import get_metrics_summary, log_metrics_summary
    
    console.print(Panel.fit(
        "[bold green]ğŸ“Š ç›‘æ§æŒ‡æ ‡[/bold green]",
        border_style="green"
    ))

    metrics = get_metrics_summary()
    
    # æ‰“å° LLM æŒ‡æ ‡
    llm_metrics = metrics.get("llm", {})
    if llm_metrics:
        console.print("\n[bold cyan]LLM Metrics[/bold cyan]")
        table = Table(box=box.ROUNDED)
        table.add_column("æŒ‡æ ‡", style="cyan")
        table.add_column("å€¼", style="green")
        
        for key, value in llm_metrics.items():
            if isinstance(value, dict) and "value" in value:
                table.add_row(value.get("name", key), str(value.get("value")))
            elif isinstance(value, dict) and "summary" in value:
                table.add_row(value.get("name", key), "")
                summary = value.get("summary", {})
                for stat_name, stat_value in summary.items():
                    table.add_row(f"  {stat_name}", f"{stat_value:.2f}")
        
        console.print(table)
    
    # æ‰“å°ç¼“å­˜æŒ‡æ ‡
    cache_metrics = metrics.get("cache", {})
    if cache_metrics:
        console.print("\n[bold cyan]Cache Metrics[/bold cyan]")
        table = Table(box=box.ROUNDED)
        table.add_column("æŒ‡æ ‡", style="cyan")
        table.add_column("å€¼", style="green")
        
        for key, value in cache_metrics.items():
            if isinstance(value, dict) and "value" in value:
                table.add_row(value.get("name", key), str(value.get("value")))
        
        console.print(table)
    
    # æ‰“å°æ€§èƒ½æŒ‡æ ‡
    perf_metrics = metrics.get("performance", {})
    if perf_metrics:
        console.print("\n[bold cyan]Performance Metrics[/bold cyan]")
        table = Table(box=box.ROUNDED)
        table.add_column("æŒ‡æ ‡", style="cyan")
        table.add_column("å€¼", style="green")
        
        for key, value in perf_metrics.items():
            if isinstance(value, dict) and "summary" in value:
                table.add_row(value.get("name", key), "")
                summary = value.get("summary", {})
                for stat_name, stat_value in summary.items():
                    table.add_row(f"  {stat_name}", f"{stat_value:.2f}")
        
        console.print(table)
    
    # è®°å½•åˆ°æ—¥å¿—
    log_metrics_summary()


@app.command(name="testability")
def analyze_testability(
    source_file: Path = typer.Argument(
        ..., help="æºæ–‡ä»¶è·¯å¾„", exists=True, file_okay=True, dir_okay=False
    ),
    output_format: str = typer.Option(
        "summary", "--output", "-o",
        help="è¾“å‡ºæ ¼å¼ (summary/json/detailed)"
    ),
    show_refactoring: bool = typer.Option(
        True, "--refactoring", "-r",
        help="æ˜¾ç¤ºé‡æ„å»ºè®®"
    ),
) -> None:
    """åˆ†æä»£ç å¯æµ‹è¯•æ€§."""
    from ut_agent.tools.testability_analyzer import (
        TestabilityAnalyzer,
        RefactoringAdvisor,
    )
    
    console.print(Panel.fit(
        "[bold cyan]ğŸ” å¯æµ‹è¯•æ€§åˆ†æ[/bold cyan]",
        border_style="cyan"
    ))
    
    analyzer = TestabilityAnalyzer(str(source_file.parent))
    
    with open(source_file, 'r', encoding='utf-8') as f:
        source_code = f.read()
    
    score = analyzer.analyze_file(str(source_file), source_code)
    
    if output_format == "json":
        console.print_json(data=score.to_dict())
    else:
        console.print(f"\n[bold]å¯æµ‹è¯•æ€§è¯„åˆ†: {score.overall_score:.1f}/100[/bold]")
        
        table = Table(box=box.ROUNDED)
        table.add_column("ç»´åº¦", style="cyan")
        table.add_column("è¯„åˆ†", style="green")
        
        table.add_row("ä¾èµ–ç®¡ç†", f"{score.dependency_score:.1f}")
        table.add_row("è€¦åˆåº¦", f"{score.coupling_score:.1f}")
        table.add_row("å¤æ‚åº¦", f"{score.complexity_score:.1f}")
        table.add_row("è®¾è®¡è´¨é‡", f"{score.design_score:.1f}")
        
        console.print(table)
        
        if score.issues:
            console.print(f"\n[bold yellow]å‘ç° {len(score.issues)} ä¸ªé—®é¢˜[/bold yellow]")
            
            for issue in score.issues[:10]:
                severity_color = {
                    "critical": "red",
                    "high": "yellow",
                    "medium": "cyan",
                    "low": "blue",
                }.get(issue.severity.value, "white")
                
                console.print(f"\n[{severity_color}]{issue.severity.value.upper()}[/{severity_color}] {issue.issue_type.value}")
                console.print(f"  ä½ç½®: {source_file.name}:{issue.line_number}")
                console.print(f"  æè¿°: {issue.description}")
                
                if show_refactoring:
                    console.print(f"  [green]å»ºè®®: {issue.refactoring_suggestion}[/green]")
        
        if show_refactoring and score.issues:
            console.print("\n[bold cyan]ğŸ”§ é‡æ„å»ºè®®[/bold cyan]")
            advisor = RefactoringAdvisor()
            report = advisor.generate_refactoring_report(score.issues)
            
            for refactoring in report["refactorings"][:5]:
                console.print(f"\n[cyan]{refactoring['suggestion']['description']}[/cyan]")
                for step in refactoring['suggestion']['applies_to']:
                    console.print(f"  - {step}")


@app.command(name="stability")
def analyze_stability(
    project: Path = typer.Argument(
        ..., help="é¡¹ç›®è·¯å¾„", exists=True, file_okay=False, dir_okay=True
    ),
    history_file: Optional[Path] = typer.Option(
        None, "--history", "-h",
        help="æµ‹è¯•æ‰§è¡Œå†å²æ–‡ä»¶è·¯å¾„"
    ),
    runs: int = typer.Option(
        5, "--runs", "-n",
        help="ç¨³å®šæ€§æ£€æµ‹è¿è¡Œæ¬¡æ•°"
    ),
    output_format: str = typer.Option(
        "summary", "--output", "-o",
        help="è¾“å‡ºæ ¼å¼ (summary/json)"
    ),
) -> None:
    """åˆ†ææµ‹è¯•ç¨³å®šæ€§."""
    from ut_agent.tools.flaky_detector import (
        StabilityAnalyzer,
        FlakyTestDetector,
    )
    
    console.print(Panel.fit(
        "[bold yellow]âš¡ æµ‹è¯•ç¨³å®šæ€§åˆ†æ[/bold yellow]",
        border_style="yellow"
    ))
    
    detector = FlakyTestDetector(
        history_file=str(history_file) if history_file else None
    )
    
    analyzer = StabilityAnalyzer(
        str(project),
        history_file=str(history_file) if history_file else None,
    )
    
    flaky_tests = detector.detect_flaky_tests()
    
    if output_format == "json":
        result = {
            "total_flaky": len(flaky_tests),
            "flaky_tests": [t.to_dict() for t in flaky_tests],
        }
        console.print_json(data=result)
    else:
        if flaky_tests:
            console.print(f"\n[bold red]å‘ç° {len(flaky_tests)} ä¸ªä¸ç¨³å®šæµ‹è¯•[/bold red]")
            
            for test in flaky_tests:
                console.print(f"\n[yellow]âš ï¸ {test.test_class}.{test.test_method}[/yellow]")
                console.print(f"  Flakyè¯„åˆ†: {test.flaky_score:.2f}")
                console.print(f"  é€šè¿‡/å¤±è´¥: {test.pass_count}/{test.fail_count}")
                console.print(f"  åŸå› : {', '.join(c.value for c in test.detected_causes)}")
                
                if test.suggested_fixes:
                    console.print("  [green]ä¿®å¤å»ºè®®:[/green]")
                    for fix in test.suggested_fixes[:3]:
                        console.print(f"    - {fix}")
        else:
            console.print("\n[bold green]âœ… æœªå‘ç°ä¸ç¨³å®šæµ‹è¯•[/bold green]")


@app.command(name="debt")
def manage_debt(
    project: Path = typer.Argument(
        ..., help="é¡¹ç›®è·¯å¾„", exists=True, file_okay=False, dir_okay=True
    ),
    action: str = typer.Argument(
        "report", help="æ“ä½œ: report/add/resolve/summary"
    ),
    debt_type: Optional[str] = typer.Option(
        None, "--type", "-t",
        help="å€ºåŠ¡ç±»å‹ (missing_tests/low_coverage/flaky_testsç­‰)"
    ),
    description: Optional[str] = typer.Option(
        None, "--description", "-d",
        help="å€ºåŠ¡æè¿°"
    ),
    priority: str = typer.Option(
        "medium", "--priority", "-p",
        help="ä¼˜å…ˆçº§ (critical/high/medium/low)"
    ),
    debt_id: Optional[str] = typer.Option(
        None, "--id",
        help="å€ºåŠ¡ID (ç”¨äºresolveæ“ä½œ)"
    ),
) -> None:
    """ç®¡ç†æµ‹è¯•å€ºåŠ¡."""
    from ut_agent.tools.test_debt_tracker import (
        TestDebtTracker,
        DebtType,
        DebtPriority,
    )
    
    storage_path = str(project / ".ut-agent" / "debt")
    tracker = TestDebtTracker(str(project), storage_path=storage_path)
    
    if action == "report":
        console.print(Panel.fit(
            "[bold red]ğŸ“‹ æµ‹è¯•å€ºåŠ¡æŠ¥å‘Š[/bold red]",
            border_style="red"
        ))
        
        report = tracker.get_debt_report()
        
        table = Table(box=box.ROUNDED)
        table.add_column("æŒ‡æ ‡", style="cyan")
        table.add_column("å€¼", style="green")
        
        table.add_row("æ€»å€ºåŠ¡è¯„åˆ†", f"{report.total_debt_score:.2f}")
        table.add_row("æ€»å€ºåŠ¡é¡¹", str(report.total_items))
        table.add_row("å¾…å¤„ç†é¡¹", str(report.open_items))
        table.add_row("å…³é”®é¡¹", str(report.critical_items))
        
        console.print(table)
        
        if report.recommendations:
            console.print("\n[bold cyan]ğŸ’¡ å»ºè®®[/bold cyan]")
            for rec in report.recommendations:
                console.print(f"  - {rec}")
        
    elif action == "add":
        if not debt_type or not description:
            console.print("[red]é”™è¯¯: addæ“ä½œéœ€è¦ --type å’Œ --description å‚æ•°[/red]")
            raise typer.Exit(1)
        
        try:
            dtype = DebtType(debt_type)
            dpriority = DebtPriority(priority)
        except ValueError as e:
            console.print(f"[red]é”™è¯¯: æ— æ•ˆçš„å€ºåŠ¡ç±»å‹æˆ–ä¼˜å…ˆçº§ - {e}[/red]")
            raise typer.Exit(1)
        
        item = tracker.add_debt_item(
            debt_type=dtype,
            file_path=str(project),
            description=description,
            impact_score=5.0,
            priority=dpriority,
        )
        
        console.print(f"[green]âœ“ å·²æ·»åŠ å€ºåŠ¡é¡¹: {item.debt_id}[/green]")
        
    elif action == "resolve":
        if not debt_id:
            console.print("[red]é”™è¯¯: resolveæ“ä½œéœ€è¦ --id å‚æ•°[/red]")
            raise typer.Exit(1)
        
        if tracker.resolve_debt(debt_id):
            console.print(f"[green]âœ“ å·²è§£å†³å€ºåŠ¡é¡¹: {debt_id}[/green]")
        else:
            console.print(f"[red]é”™è¯¯: æœªæ‰¾åˆ°å€ºåŠ¡é¡¹: {debt_id}[/red]")
            raise typer.Exit(1)
    
    elif action == "summary":
        summary = tracker.get_debt_summary()
        console.print_json(data=summary)
    
    else:
        console.print(f"[red]é”™è¯¯: æœªçŸ¥æ“ä½œ '{action}'[/red]")
        console.print("å¯ç”¨æ“ä½œ: report, add, resolve, summary")
        raise typer.Exit(1)


@app.command(name="quality")
def analyze_quality(
    test_file: Path = typer.Argument(
        ..., help="æµ‹è¯•æ–‡ä»¶è·¯å¾„", exists=True, file_okay=True, dir_okay=False
    ),
    source_file: Optional[Path] = typer.Option(
        None, "--source", "-s",
        help="å¯¹åº”æºæ–‡ä»¶è·¯å¾„"
    ),
    mutation_report: Optional[Path] = typer.Option(
        None, "--mutation", "-m",
        help="å˜å¼‚æµ‹è¯•æŠ¥å‘Šè·¯å¾„ (JSON)"
    ),
    coverage_report: Optional[Path] = typer.Option(
        None, "--coverage", "-c",
        help="è¦†ç›–ç‡æŠ¥å‘Šè·¯å¾„ (JSON)"
    ),
    output_format: str = typer.Option(
        "summary", "--output", "-o",
        help="è¾“å‡ºæ ¼å¼ (summary/json/detailed)"
    ),
) -> None:
    """åˆ†ææµ‹è¯•è´¨é‡."""
    from ut_agent.tools.enhanced_quality_scorer import EnhancedQualityScorer
    import json
    
    console.print(Panel.fit(
        "[bold green]ğŸ“Š æµ‹è¯•è´¨é‡åˆ†æ[/bold green]",
        border_style="green"
    ))
    
    with open(test_file, 'r', encoding='utf-8') as f:
        test_code = f.read()
    
    source_code = ""
    if source_file and source_file.exists():
        with open(source_file, 'r', encoding='utf-8') as f:
            source_code = f.read()
    
    mutation_data = None
    if mutation_report and mutation_report.exists():
        with open(mutation_report, 'r', encoding='utf-8') as f:
            mutation_data = json.load(f)
    
    coverage_data = None
    if coverage_report and coverage_report.exists():
        with open(coverage_report, 'r', encoding='utf-8') as f:
            coverage_data = json.load(f)
    
    scorer = EnhancedQualityScorer()
    report = scorer.generate_comprehensive_report(
        test_code=test_code,
        source_code=source_code,
        test_file=str(test_file),
        source_file=str(source_file) if source_file else None,
        mutation_report=mutation_data,
        coverage_report=coverage_data,
    )
    
    if output_format == "json":
        console.print_json(data=report.to_dict())
    else:
        console.print(f"\n[bold]æ•´ä½“è´¨é‡è¯„åˆ†: {report.overall_score:.1f}/100 ({report.grade})[/bold]")
        
        table = Table(box=box.ROUNDED)
        table.add_column("ç»´åº¦", style="cyan")
        table.add_column("è¯„åˆ†", style="green")
        table.add_column("çŠ¶æ€", style="yellow")
        
        scores = [
            ("æœ‰æ•ˆæ€§", report.effectiveness_score),
            ("ä»£ç è´¨é‡", report.code_quality_score),
            ("è¦†ç›–æ·±åº¦", report.coverage_depth_score),
            ("å˜å¼‚æµ‹è¯•", report.mutation_score),
            ("ç¨³å®šæ€§", report.stability_score),
            ("å¯æµ‹è¯•æ€§", report.testability_score),
        ]
        
        for name, score in scores:
            status = "âœ“" if score >= 70 else "âš " if score >= 50 else "âœ—"
            table.add_row(name, f"{score:.1f}", status)
        
        console.print(table)
        
        if report.critical_issues:
            console.print(f"\n[bold red]ğŸš¨ å…³é”®é—®é¢˜[/bold red]")
            for issue in report.critical_issues:
                console.print(f"  - {issue}")
        
        if report.recommendations:
            console.print(f"\n[bold cyan]ğŸ’¡ æ”¹è¿›å»ºè®®[/bold cyan]")
            for rec in report.recommendations:
                console.print(f"  - {rec}")
        
        if report.improvement_priorities:
            console.print(f"\n[bold yellow]ğŸ¯ ä¼˜å…ˆæ”¹è¿›é¡¹[/bold yellow]")
            for item in report.improvement_priorities:
                console.print(f"  {item['priority']}. {item['action']} (å½“å‰: {item['current_score']:.1f}, ç›®æ ‡: {item['target_score']})")


async def run_generation_workflow(
    project_path: str,
    project_type: str,
    coverage_target: float,
    max_iterations: int,
    llm_provider: str,
    dry_run: bool,
    incremental: bool = False,
    base_ref: Optional[str] = None,
    head_ref: Optional[str] = None,
    html_report: bool = False,
) -> None:
    """è¿è¡Œç”Ÿæˆå·¥ä½œæµ."""
    # åˆ›å»ºåˆå§‹çŠ¶æ€
    initial_state: AgentState = {
        "project_path": project_path,
        "project_type": project_type if project_type != "auto" else "",
        "build_tool": "",
        "target_files": [],
        "coverage_target": coverage_target,
        "max_iterations": max_iterations,
        "incremental": incremental,
        "base_ref": base_ref,
        "head_ref": head_ref,
        "iteration_count": 0,
        "status": "started",
        "message": "å¼€å§‹æ‰§è¡Œ...",
        "analyzed_files": [],
        "code_changes": [],
        "change_summaries": [],
        "generated_tests": [],
        "coverage_report": None,
        "current_coverage": 0.0,
        "coverage_gaps": [],
        "improvement_plan": None,
        "output_path": None,
        "summary": None,
        "html_report_path": None,
    }

    # åˆ›å»ºå›¾
    graph = create_test_generation_graph()

    # è¿è¡Œ
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console,
    ) as progress:
        task = progress.add_task("[cyan]æ­£åœ¨ç”Ÿæˆæµ‹è¯•...", total=None)

        result = None
        async for event in graph.astream(
            initial_state,
            config={"configurable": {"llm_provider": llm_provider}},
        ):
            for node_name, node_data in event.items():
                if isinstance(node_data, dict):
                    status = node_data.get("status", "")
                    message = node_data.get("message", "")
                    progress.update(task, description=f"[cyan][{node_name}] {message}")
                    result = node_data

        progress.update(task, description="[green]âœ“ å®Œæˆ!")

    # æ˜¾ç¤ºç»“æœ
    if result:
        display_results(result)


def display_results(result: dict) -> None:
    """æ˜¾ç¤ºç»“æœ."""
    console.print()
    console.print(Panel.fit(
        "[bold green]ğŸ“ˆ æ‰§è¡Œç»“æœ[/bold green]",
        border_style="green"
    ))

    status = result.get("status", "")
    if status == "completed":
        console.print("[bold green]âœ… æµ‹è¯•ç”Ÿæˆå®Œæˆ![/bold green]")
    elif status == "target_reached":
        console.print("[bold green]ğŸ¯ è¦†ç›–ç‡ç›®æ ‡å·²è¾¾æˆ![/bold green]")
    elif status == "max_iterations_reached":
        console.print("[bold yellow]â¹ï¸ è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°[/bold yellow]")
    else:
        console.print(f"çŠ¶æ€: {status}")

    # è¦†ç›–ç‡æŠ¥å‘Š
    coverage_report = result.get("coverage_report")
    if coverage_report:
        console.print()
        console.print("[bold cyan]ğŸ“Š è¦†ç›–ç‡ç»Ÿè®¡[/bold cyan]")

        table = Table(box=box.ROUNDED)
        table.add_column("æŒ‡æ ‡", style="cyan")
        table.add_column("è¦†ç›–ç‡", style="green")
        table.add_column("è¯¦æƒ…", style="yellow")

        table.add_row(
            "æ€»ä½“è¦†ç›–ç‡",
            f"{coverage_report.overall_coverage:.2f}%",
            ""
        )
        table.add_row(
            "è¡Œè¦†ç›–ç‡",
            f"{coverage_report.line_coverage:.2f}%",
            f"{coverage_report.covered_lines}/{coverage_report.total_lines}"
        )
        table.add_row(
            "åˆ†æ”¯è¦†ç›–ç‡",
            f"{coverage_report.branch_coverage:.2f}%",
            f"{coverage_report.covered_branches}/{coverage_report.total_branches}"
        )
        table.add_row(
            "æ–¹æ³•è¦†ç›–ç‡",
            f"{coverage_report.method_coverage:.2f}%",
            ""
        )
        table.add_row(
            "ç±»è¦†ç›–ç‡",
            f"{coverage_report.class_coverage:.2f}%",
            ""
        )

        console.print(table)

    # ç”Ÿæˆçš„æµ‹è¯•æ–‡ä»¶
    generated_tests = result.get("generated_tests", [])
    if generated_tests:
        console.print()
        console.print(f"[bold cyan]ğŸ§ª ç”Ÿæˆçš„æµ‹è¯•æ–‡ä»¶ ({len(generated_tests)}ä¸ª)[/bold cyan]")

        for test_file in generated_tests:
            console.print(f"  [green]âœ“[/green] {test_file.test_file_path}")

    # æ‘˜è¦
    summary = result.get("summary")
    if summary:
        console.print()
        console.print("[bold cyan]ğŸ“ æ‘˜è¦[/bold cyan]")
        console.print(summary)


if __name__ == "__main__":
    app()
